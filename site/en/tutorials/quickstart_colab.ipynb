{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaryab13/3D-Portfolio--Three-js-/blob/main/site/en/tutorials/quickstart_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yjO7sjyaqRNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Data Preparation\n",
        "# -----------------------------\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize image data to [0, 1] range\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat  = to_categorical(y_test, num_classes)\n",
        "\n",
        "# -----------------------------\n",
        "# Model 1: MLP Network\n",
        "# -----------------------------\n",
        "# The MLP will flatten the 32x32x3 image into a 3072-element vector\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(Flatten(input_shape=x_train.shape[1:]))  # Converts (32, 32, 3) to (3072,)\n",
        "model_mlp.add(Dense(512, activation='relu'))\n",
        "model_mlp.add(Dropout(0.2))\n",
        "model_mlp.add(Dense(256, activation='relu'))\n",
        "model_mlp.add(Dropout(0.2))\n",
        "model_mlp.add(Dense(128, activation='relu'))\n",
        "model_mlp.add(Dropout(0.2))\n",
        "model_mlp.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the MLP model\n",
        "model_mlp.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the MLP model\n",
        "print(\"Training MLP model...\")\n",
        "history_mlp = model_mlp.fit(x_train, y_train_cat,\n",
        "                            batch_size=128,\n",
        "                            epochs=20,\n",
        "                            validation_split=0.1,\n",
        "                            verbose=1)\n",
        "\n",
        "# Evaluate the MLP model on test data\n",
        "score_mlp = model_mlp.evaluate(x_test, y_test_cat, verbose=0)\n",
        "print(\"\\nMLP Model Evaluation:\")\n",
        "print(\"Test Loss: {:.4f}\".format(score_mlp[0]))\n",
        "print(\"Test Accuracy: {:.4f}\".format(score_mlp[1]))\n",
        "\n",
        "# -----------------------------\n",
        "# Model 2: CNN Network\n",
        "# -----------------------------\n",
        "# The CNN model leverages convolutional layers to extract spatial features.\n",
        "model_cnn = Sequential()\n",
        "\n",
        "# First convolution block\n",
        "model_cnn.add(Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                     input_shape=x_train.shape[1:]))\n",
        "model_cnn.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "\n",
        "# Second convolution block\n",
        "model_cnn.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model_cnn.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected classifier\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(512, activation='relu'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the CNN model\n",
        "model_cnn.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "print(\"\\nTraining CNN model...\")\n",
        "history_cnn = model_cnn.fit(x_train, y_train_cat,\n",
        "                            batch_size=64,\n",
        "                            epochs=20,\n",
        "                            validation_split=0.1,\n",
        "                            verbose=1)\n",
        "\n",
        "# Evaluate the CNN model on test data\n",
        "score_cnn = model_cnn.evaluate(x_test, y_test_cat, verbose=0)\n",
        "print(\"\\nCNN Model Evaluation:\")\n",
        "print(\"Test Loss: {:.4f}\".format(score_cnn[0]))\n",
        "print(\"Test Accuracy: {:.4f}\".format(score_cnn[1]))\n",
        "\n",
        "# -----------------------------\n",
        "# (Optional) Plotting Training History\n",
        "# -----------------------------\n",
        "# You can visualize the training history for both models if desired.\n",
        "\n",
        "# Plot for MLP\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_mlp.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_mlp.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('MLP Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_mlp.history['loss'], label='Train Loss')\n",
        "plt.plot(history_mlp.history['val_loss'], label='Val Loss')\n",
        "plt.title('MLP Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot for CNN\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_cnn.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('CNN Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_cnn.history['loss'], label='Train Loss')\n",
        "plt.plot(history_cnn.history['val_loss'], label='Val Loss')\n",
        "plt.title('CNN Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VLdZ4fDqSoS",
        "outputId": "b88b8362-c027-4782-8aca-72d76203d04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLP model...\n",
            "Epoch 1/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.2057 - loss: 2.1611 - val_accuracy: 0.3352 - val_loss: 1.8254\n",
            "Epoch 2/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.3191 - loss: 1.8686 - val_accuracy: 0.3774 - val_loss: 1.7458\n",
            "Epoch 3/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.3458 - loss: 1.7999 - val_accuracy: 0.3674 - val_loss: 1.7330\n",
            "Epoch 4/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.3646 - loss: 1.7591 - val_accuracy: 0.3980 - val_loss: 1.6879\n",
            "Epoch 5/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.3631 - loss: 1.7453 - val_accuracy: 0.4028 - val_loss: 1.6573\n",
            "Epoch 6/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.3814 - loss: 1.7108 - val_accuracy: 0.4120 - val_loss: 1.6458\n",
            "Epoch 7/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.3916 - loss: 1.6785 - val_accuracy: 0.4230 - val_loss: 1.6231\n",
            "Epoch 8/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.3991 - loss: 1.6666 - val_accuracy: 0.4192 - val_loss: 1.6082\n",
            "Epoch 9/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.4010 - loss: 1.6582 - val_accuracy: 0.4298 - val_loss: 1.5859\n",
            "Epoch 10/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.4039 - loss: 1.6394 - val_accuracy: 0.4304 - val_loss: 1.6031\n",
            "Epoch 11/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.4171 - loss: 1.6233 - val_accuracy: 0.4320 - val_loss: 1.5881\n",
            "Epoch 12/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.4146 - loss: 1.6139 - val_accuracy: 0.4352 - val_loss: 1.6000\n",
            "Epoch 13/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.4185 - loss: 1.6092 - val_accuracy: 0.4378 - val_loss: 1.5622\n",
            "Epoch 14/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.4208 - loss: 1.6036 - val_accuracy: 0.4332 - val_loss: 1.5615\n",
            "Epoch 15/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.4282 - loss: 1.5874 - val_accuracy: 0.4560 - val_loss: 1.5420\n",
            "Epoch 16/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.4308 - loss: 1.5766 - val_accuracy: 0.4410 - val_loss: 1.5518\n",
            "Epoch 17/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.4316 - loss: 1.5752 - val_accuracy: 0.4516 - val_loss: 1.5326\n",
            "Epoch 18/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.4271 - loss: 1.5803 - val_accuracy: 0.4544 - val_loss: 1.5288\n",
            "Epoch 19/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.4403 - loss: 1.5511 - val_accuracy: 0.4590 - val_loss: 1.5293\n",
            "Epoch 20/20\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.4433 - loss: 1.5480 - val_accuracy: 0.4582 - val_loss: 1.5202\n",
            "\n",
            "MLP Model Evaluation:\n",
            "Test Loss: 1.5064\n",
            "Test Accuracy: 0.4626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN model...\n",
            "Epoch 1/20\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 385ms/step - accuracy: 0.3403 - loss: 1.7883 - val_accuracy: 0.5808 - val_loss: 1.1706\n",
            "Epoch 2/20\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 366ms/step - accuracy: 0.5677 - loss: 1.2057 - val_accuracy: 0.6382 - val_loss: 1.0137\n",
            "Epoch 3/20\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 365ms/step - accuracy: 0.6321 - loss: 1.0305 - val_accuracy: 0.6912 - val_loss: 0.8918\n",
            "Epoch 4/20\n",
            "\u001b[1m642/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 352ms/step - accuracy: 0.6813 - loss: 0.8973"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart_colab.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}